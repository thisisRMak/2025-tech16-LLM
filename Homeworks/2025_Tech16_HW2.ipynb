{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkLTibeRL+j8kyOiKqhAfP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thisisRMak/2025-tech16-LLM/blob/main/2025_Tech16_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tech16 HW2\n",
        "\n",
        "1. Create a summarization using langchain and compare the \"stuff\" and \"map-reduce\" methods\n",
        "\n",
        "  - Load and run URLs and PDFs via stuff and map-reduce. The difference between the two wasn't very clear from these examples, but map-reduce seemed to take longer to run.\n",
        "  - Examples\n",
        "    1. Science Fiction short story by Isaac Asimov (URL)\n",
        "    2. George Washington Farewell - Presidential address (URL)\n",
        "    3. Attention is All You Need (pdf)\n",
        "\n",
        "2. Extra credit: explore langchain and find one additional thing to do!\n",
        "\n",
        "  - Created a chatbot that reads a document and answers questions about it using GPT-4o.\n",
        "  - For example, we make the agent read the Attention is All You Need Paper and answer questions about it, like what is a transformer and write a simple example to demonstrate how a Transformer is implemented?"
      ],
      "metadata": {
        "id": "2pNrNunQirTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community pypdf langchain-openai\n",
        "!pip install unstructured"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9pPD7CyjWtm",
        "outputId": "e479e370-3c29-4837-d8cf-e758aeadbb9d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.17)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.3.0)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.5)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.35)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.18 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.18)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.8)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.61.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.11/dist-packages (0.16.20)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.11/dist-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.3.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from unstructured) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from unstructured) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.13.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (from unstructured) (2.14.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from unstructured) (0.6.7)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.11/dist-packages (from unstructured) (2025.2.8)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.0.9)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.26.4)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.11/dist-packages (from unstructured) (3.12.1)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.11/dist-packages (from unstructured) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.12.2)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.11/dist-packages (from unstructured) (0.30.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.17.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.9.5)\n",
            "Requirement already satisfied: python-oxmsg in /usr/local/lib/python3.11/dist-packages (from unstructured) (0.0.2)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->unstructured) (2.6)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->unstructured) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->unstructured) (0.9.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (2024.11.6)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.11/dist-packages (from python-oxmsg->unstructured) (0.47)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured) (2025.1.31)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (24.1.0)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (43.0.3)\n",
            "Requirement already satisfied: eval-type-backport>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (0.2.2)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Requirement already satisfied: pydantic>=2.10.3 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (2.10.6)\n",
            "Requirement already satisfied: pypdf>=4.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (5.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (2.8.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->unstructured-client->unstructured) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->unstructured-client->unstructured) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "open_ai_key = userdata.get('open_ai_key')\n",
        "client = OpenAI(api_key = open_ai_key)\n",
        "\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(temperature=0.1, model_name=\"gpt-4-turbo-preview\", api_key=open_ai_key)\n",
        "chainstuff = load_summarize_chain(llm, chain_type=\"stuff\")\n",
        "chainmapreduce = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
        "\n",
        "def summarize(\n",
        "    pages,\n",
        "    chain_type = \"stuff\"\n",
        "    ):\n",
        "\n",
        "  llm = ChatOpenAI(temperature=0.1, model_name=\"gpt-4-turbo-preview\", api_key=open_ai_key)\n",
        "  chain = load_summarize_chain(llm, chain_type=chain_type)\n",
        "  res = chain.invoke(pages)\n",
        "  return res['output_text']\n"
      ],
      "metadata": {
        "id": "88oqEV2cjijU"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import UnstructuredURLLoader\n",
        "\n",
        "def load_url(url):\n",
        "\n",
        "  loader = UnstructuredURLLoader(urls=[url])\n",
        "  data = loader.load()\n",
        "  return data\n",
        "\n"
      ],
      "metadata": {
        "id": "VHXBDxVtySic"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "def load_pdf(pdf_filename):\n",
        "  loader = PyPDFLoader(pdf_filename)\n",
        "  pages = loader.load_and_split()\n",
        "  return pages"
      ],
      "metadata": {
        "id": "kT0C9RaM0xEX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarize a Science Fiction short story"
      ],
      "metadata": {
        "id": "HfbeVNXnxJci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://users.ece.cmu.edu/~gamvrosi/thelastq.html\"\n",
        "\n",
        "data = load_url(url)\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8w4URKuvXZ8",
        "outputId": "bd08e87c-b6c7-47e9-9e7f-9a23d0468361"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': 'https://users.ece.cmu.edu/~gamvrosi/thelastq.html'}, page_content='The Last Question\\n\\nBy Isaac Asimov\\n\\nIsaac Asimov was the most prolific science fiction author of all time. In fifty years he averaged a new magazine article, short story, or book every two weeks, and most of that on a manual typewriter. Asimov thought that The Last Question, first copyrighted in 1956, was his best short story ever. Even if you do not have the background in science to be familiar with all of the concepts presented here, the ending packs more impact than any other book that I\\'ve ever read. Don\\'t read the end of the story first!\\n\\nThis is by far my favorite story of all those I have written. After all, I undertook to tell several trillion years of human history in the space of a short story and I leave it to you as to how well I succeeded. I also undertook another task, but I won\\'t tell you what that was lest l spoil the story for you. It is a curious fact that innumerable readers have asked me if I wrote this story. They seem never to remember the title of the story or (for sure) the author, except for the vague thought it might be me. But, of course, they never forget the story itself especially the ending. The idea seems to drown out everything -- and I\\'m satisfied that it should.\\n\\nThe last question was asked for the first time, half in jest, on May 21, 2061, at a time when humanity first stepped into the light. The question came about as a result of a five-dollar bet over highballs, and it happened this way:\\n\\nAlexander Adell and Bertram Lupov were two of the faithful attendants of Multivac. As well as any human beings could, they knew what lay behind the cold, clicking, flashing face -- miles and miles of face -- of that giant computer. They had at least a vague notion of the general plan of relays and circuits that had long since grown past the point where any single human could possibly have a firm grasp of the whole.\\n\\nMultivac was self-adjusting and self-correcting. It had to be, for nothing human could adjust and correct it quickly enough or even adequately enough. So Adell and Lupov attended the monstrous giant only lightly and superficially, yet as well as any men could. They fed it data, adjusted questions to its needs and translated the answers that were issued. Certainly they, and all others like them, were fully entitled to share in the glory that was Multivac\\'s.\\n\\nFor decades, Multivac had helped design the ships and plot the trajectories that enabled man to reach the Moon, Mars, and Venus, but past that, Earth\\'s poor resources could not support the ships. Too much energy was needed for the long trips. Earth exploited its coal and uranium with increasing efficiency, but there was only so much of both.\\n\\nBut slowly Multivac learned enough to answer deeper questions more fundamentally, and on May 14, 2061, what had been theory, became fact.\\n\\nThe energy of the sun was stored, converted, and utilized directly on a planet-wide scale. All Earth turned off its burning coal, its fissioning uranium, and flipped the switch that connected all of it to a small station, one mile in diameter, circling the Earth at half the distance of the Moon. All Earth ran by invisible beams of sunpower.\\n\\nSeven days had not sufficed to dim the glory of it and Adell and Lupov finally managed to escape from the public functions, and to meet in quiet where no one would think of looking for them, in the deserted underground chambers, where portions of the mighty buried body of Multivac showed. Unattended, idling, sorting data with contented lazy clickings, Multivac, too, had earned its vacation and the boys appreciated that. They had no intention, originally, of disturbing it.\\n\\nThey had brought a bottle with them, and their only concern at the moment was to relax in the company of each other and the bottle.\\n\\n\"It\\'s amazing when you think of it,\" said Adell. His broad face had lines of weariness in it, and he stirred his drink slowly with a glass rod, watching the cubes of ice slur clumsily about. \"All the energy we can possibly ever use for free. Enough energy, if we wanted to draw on it, to melt all Earth into a big drop of impure liquid iron, and still never miss the energy so used. All the energy we could ever use, forever and forever and forever.\"\\n\\nLupov cocked his head sideways. He had a trick of doing that when he wanted to be contrary, and he wanted to be contrary now, partly because he had had to carry the ice and glassware. \"Not forever,\" he said.\\n\\n\"Oh, hell, just about forever. Till the sun runs down, Bert.\"\\n\\n\"That\\'s not forever.\"\\n\\n\"All right, then. Billions and billions of years. Ten billion, maybe. Are you satisfied?\"\\n\\nLupov put his fingers through his thinning hair as though to reassure himself that some was still left and sipped gently at his own drink. \"Ten billion years isn\\'t forever.\"\\n\\n\"Well, it will last our time, won\\'t it?\"\\n\\n\"So would the coal and uranium.\"\\n\\n\"All right, but now we can hook up each individual spaceship to the Solar Station, and it can go to Pluto and back a million times without ever worrying about fuel. You can\\'t do that on coal and uranium. Ask Multivac, if you don\\'t believe me.\\n\\n\"I don\\'t have to ask Multivac. I know that.\"\\n\\n\"Then stop running down what Multivac\\'s done for us,\" said Adell, blazing up, \"It did all right.\"\\n\\n\"Who says it didn\\'t? What I say is that a sun won\\'t last forever. That\\'s all I\\'m saying. We\\'re safe for ten billion years, but then what?\" Lupow pointed a slightly shaky finger at the other. \"And don\\'t say we\\'ll switch to another sun.\"\\n\\nThere was silence for a while. Adell put his glass to his lips only occasionally, and Lupov\\'s eyes slowly closed. They rested.\\n\\nThen Lupov\\'s eyes snapped open. \"You\\'re thinking we\\'ll switch to another sun when ours is done, aren\\'t you?\"\\n\\n\"I\\'m not thinking.\"\\n\\n\"Sure you are. You\\'re weak on logic, that\\'s the trouble with you. You\\'re like the guy in the story who was caught in a sudden shower and who ran to a grove of trees and got under one. He wasn\\'t worried, you see, because he figured when one tree got wet through, he would just get under another one.\"\\n\\n\"I get it,\" said Adell. \"Don\\'t shout. When the sun is done, the other stars will be gone, too.\"\\n\\n\"Darn right they will,\" muttered Lupov. \"It all had a beginning in the original cosmic explosion, whatever that was, and it\\'ll all have an end when all the stars run down. Some run down faster than others. Hell, the giants won\\'t last a hundred million years. The sun will last ten billion years and maybe the dwarfs will last two hundred billion for all the good they are. But just give us a trillion years and everything will be dark. Entropy has to increase to maximum, that\\'s all.\"\\n\\n\"I know all about entropy,\" said Adell, standing on his dignity.\\n\\n\"The hell you do.\"\\n\\n\"I know as much as you do.\"\\n\\n\"Then you know everything\\'s got to run down someday.\"\\n\\n\"All right. Who says they won\\'t?\"\\n\\n\"You did, you poor sap. You said we had all the energy we needed, forever. You said \\'forever.\\'\\n\\nIt was Adell\\'s turn to be contrary. \"Maybe we can build things up again someday,\" he said.\\n\\n\"Never.\"\\n\\n\"Why not? Someday.\"\\n\\n\"Never.\"\\n\\n\"Ask Multivac.\"\\n\\n\"You ask Multivac. I dare you. Five dollars says it can\\'t be done.\"\\n\\nAdell was just drunk enough to try, just sober enough to be able to phrase the necessary symbols and operations into a question which, in words, might have corresponded to this: Will mankind one day without the net expenditure of energy be able to restore the sun to its full youthfulness even after it had died of old age?\\n\\nOr maybe it could be put more simply like this: How can the net amount of entropy of the universe be massively decreased?\\n\\nMultivac fell dead and silent. The slow flashing of lights ceased, the distant sounds of clicking relays ended.\\n\\nThen, just as the frightened technicians felt they could hold their breath no longer, there was a sudden springing to life of the teletype attached to that portion of Multivac. Five words were printed: INSUFFICIENT DATA FOR MEANINGFUL ANSWER.\\n\\n\"No bet,\" whispered Lupov. They left hurriedly.\\n\\nBy next morning, the two, plagued with throbbing head and cottony mouth, had forgotten the incident.\\n\\nJerrodd, Jerrodine, and Jerrodette I and II watched the starry picture in the visiplate change as the passage through hyperspace was completed in its non-time lapse. At once, the even powdering of stars gave way to the predominance of a single bright shining disk, the size of a marble, centered on the viewing-screen.\\n\\n\"That\\'s X-23,\" said Jerrodd confidently. His thin hands clamped tightly behind his back and the knuckles whitened.\\n\\nThe little Jerrodettes, both girls, had experienced the hyperspace passage for the first time in their lives and were self-conscious over the momentary sensation of insideoutness. They buried their giggles and chased one another wildly about their mother, screaming, \"We\\'ve reached X-23 -- we\\'ve reached X-23 -- we\\'ve --\"\\n\\n\"Quiet, children.\" said Jerrodine sharply. \"Are you sure, Jerrodd?\"\\n\\n\"What is there to be but sure?\" asked Jerrodd, glancing up at the bulge of featureless metal just under the ceiling. It ran the length of the room, disappearing through the wall at either end. It was as long as the ship.\\n\\nJerrodd scarcely knew a thing about the thick rod of metal except that it was called a Microvac, that one asked it questions if one wished; that if one did not it still had its task of guiding the ship to a preordered destination; of feeding on energies from the various Sub-galactic Power Stations; of computing the equations for the hyperspatial jumps.\\n\\nJerrodd and his family had only to wait and live in the comfortable residence quarters of the ship. Someone had once told Jerrodd that the \"ac\" at the end of \"Microvac\" stood for \\'\\'automatic computer\" in ancient English, but he was on the edge of forgetting even that.\\n\\nJerrodine\\'s eyes were moist as she watched the visiplate. \"I can\\'t help it. I feel funny about leaving Earth.\"\\n\\n\"Why, for Pete\\'s sake?\" demanded Jerrodd. \"We had nothing there. We\\'ll have everything on X-23. You won\\'t be alone. You won\\'t be a pioneer. There are over a million people on the planet already. Good Lord, our great-grandchildren will be looking for new worlds because X-23 will be overcrowded.\" Then, after a reflective pause, \"I tell you, it\\'s a lucky thing the computers worked out interstellar travel the way the race is growing.\"\\n\\n\"I know, I know,\" said Jerrodine miserably.\\n\\nJerrodette I said promptly, \"Our Microvac is the best Microvac in the world.\"\\n\\n\"I think so, too,\" said Jerrodd, tousling her hair.\\n\\nIt was a nice feeling to have a Microvac of your own and Jerrodd was glad he was part of his generation and no other. In his father\\'s youth, the only computers had been tremendous machines taking up a hundred square miles of land. There was only one to a planet. Planetary ACs they were called. They had been growing in size steadily for a thousand years and then, all at once, came refinement. In place of transistors, had come molecular valves so that even the largest Planetary AC could be put into a space only half the volume of a spaceship.\\n\\nJerrodd felt uplifted, as he always did when he thought that his own personal Microvac was many times more complicated than the ancient and primitive Multivac that had first tamed the Sun, and almost as complicated as Earth\\'s Planetarv AC (the largest) that had first solved the problem of hyperspatial travel and had made trips to the stars possible.\\n\\n\"So many stars, so many planets,\" sighed Jerrodine, busy with her own thoughts. \"I suppose families will be going out to new planets forever, the way we are now.\"\\n\\n\"Not forever,\" said Jerrodd, with a smile. \"It will all stop someday, but not for billions of years. Many billions. Even the stars run down, you know. Entropy must increase.\\n\\n\"What\\'s entropy, daddy?\" shrilled Jerrodette II.\\n\\n\"Entropy, little sweet, is just a word which means the amount of running-down of the universe. Everything runs down, you know, like your little walkie-talkie robot, remember?\"\\n\\n\"Can\\'t you just put in a new power-unit, like with my robot?\"\\n\\n\"The stars are the power-units. dear. Once they\\'re gone, there are no more power-units.\"\\n\\nJerrodette I at once set up a howl. \"Don\\'t let them, daddy. Don\\'t let the stars run down.\"\\n\\n\"Now look what you\\'ve done,\" whispered Jerrodine, exasperated.\\n\\n\"How was I to know it would frighten them?\" Jerrodd whispered back,\\n\\n\"Ask the Microvac,\" wailed Jerrodette I. \"Ask him how to turn the stars on again.\"\\n\\n\"Go ahead,\" said Jerrodine. \"It will quiet them down.\" (Jerrodette II was beginning to cry, also.)\\n\\nJerrodd shrugged. \"Now, now, honeys. I\\'ll ask Microvac. Don\\'t worry, he\\'ll tell us.\"\\n\\nHe asked the Microvac, adding quickly, \"Print the answer.\"\\n\\nJerrodd cupped the strip or thin cellufilm and said cheerfully, \"See now, the Microvac says it will take care of everything when the time comes so don\\'t worry.\"\\n\\nJerrodine said, \"And now, children, it\\'s time for bed. We\\'ll be in our new home soon.\"\\n\\nJerrodd read the words on the cellufilm again before destroying it: INSUFICIENT DATA FOR MEANINGFUL ANSWER.\\n\\nHe shrugged and looked at the visiplate. X-23 was just ahead.\\n\\nVJ-23X of Lameth stared into the black depths of the three-dimensional, small-scale map of the Galaxy and said, \"Are we ridiculous, I wonder in being so concerned about the matter?\"\\n\\nMQ-17J of Nicron shook his head. \"I think not. You know the Galaxy will be filled in five years at the present rate of expansion.\"\\n\\nBoth seemed in their early twenties, both were tall and perfectly formed.\\n\\n\"Still,\" said VJ-23X, \"I hesitate to submit a pessimistic report to the Galactic Council.\"\\n\\n\"I wouldn\\'t consider any other kind of report. Stir them up a bit. We\\'ve got to stir them up.\"\\n\\nVJ-23X sighed. \"Space is infinite. A hundred billion Galaxies are there for the taking. More.\"\\n\\n\"A hundred billion is not infinite and it\\'s getting less infinite all the time. Consider! Twenty thousand years ago, mankind first solved the problem of utilizing stellar energy, and a few centuries later, interstellar travel became possible. It took mankind a million years to fill one small world and then only fifteen thousand years to fill the rest of the Galaxy. Now the population doubles every ten years --\\n\\nVJ-23X interrupted. \"We can thank immortality for that.\"\\n\\n\"Very well. Immortality exists and we have to take it into account. I admit it has its seamy side, this immortality. The Galactic AC has solved many problems for us, but in solving the problem of preventing old age and death, it has undone all its other solutions.\"\\n\\n\"Yet you wouldn\\'t want to abandon life, I suppose.\"\\n\\n\"Not at all,\" snapped MQ-17J, softening it at once to, \"Not yet. I\\'m by no means old enough. How old are you?\"\\n\\n\"Two hundred twenty-three. And you?\"\\n\\n\"I\\'m still under two hundred. --But to get back to my point. Population doubles every ten years. Once this GaIaxy is filled, we\\'ll have filled another in ten years. Another ten years and we\\'ll have filled two more. Another decade, four more. In a hundred years, we\\'ll have filled a thousand Galaxies. In a thousand years, a million Galaxies. In ten thousand years, the entire known universe. Then what?\"\\n\\nVJ-23X said, \"As a side issue, there\\'s a problem of transportation. I wonder how many sunpower units it will take to move Galaxies of individuals from one Galaxy to the next.\"\\n\\n\"A very good point. Already, mankind consumes two sunpower units per year.\"\\n\\n\"Most of it\\'s wasted. After all, our own Galaxy alone pours out a thousand sunpower units a year and we only use two of those.\"\\n\\n\"Granted, but even with a hundred per cent efficiency, we only stave off the end. Our energy requirements are going up in a geometric progression even faster than our population. We\\'ll run out of energy even sooner than we run out of Galaxies. A good point. A very good point.\"\\n\\n\"We\\'ll just have to build new stars out of interstellar gas.\"\\n\\n\"Or out of dissipated heat?\" asked MQ-17J, sarcastically.\\n\\n\"There may be some way to reverse entropy. We ought to ask the Galactic AC.\"\\n\\nVJ-23X was not really serious, but MQ-17J pulled out his AC-contact from his pocket and placed it on the table before him.\\n\\n\"I\\'ve half a mind to,\" he said. \"It\\'s something the human race will have to face someday.\"\\n\\nHe stared somberly at his small AC-contact. It was only two inches cubed and nothing in itself, but it was connected through hyperspace with the great Galactic AC that served all mankind. Hyperspace considered, it was an integral part of the Galactic AC.\\n\\nMQ-17J paused to wonder if someday in his immortal life he would get to see the Galactic AC. It was on a little world of its own, a spider webbing of force-beams holding the matter within which surges of submesons took the place of the old clumsy molecular valves. Yet despite its sub-etheric workings, the Galactic AC was known to be a full thousand feet across.\\n\\nMQ-17J asked suddenly of his AC-contact, \"Can entropy ever be reversed?\"\\n\\nVJ-23X looked startled and said at once, \"Oh, say, I didn\\'t really mean to have you ask that.\"\\n\\n\"Why not?\"\\n\\n\"We both know entropy can\\'t be reversed. You can\\'t turn smoke and ash back into a tree.\"\\n\\n\"Do you have trees on your world?\" asked MQ-17J.\\n\\nThe sound of the Galactic AC startled them into silence. Its voice came thin and beautiful out of the small AC-contact on the desk. It said: THERE IS INSUFFICIENT DATA FOR A MEANINGFUL ANSWER.\\n\\nVJ-23X said, \"See!\"\\n\\nThe two men thereupon returned to the question of the report they were to make to the Galactic Council.\\n\\nZee Prime\\'s mind spanned the new Galaxy with a faint interest in the countless twists of stars that powdered it. He had never seen this one before. Would he ever see them all? So many of them, each with its load of humanity. --But a load that was almost a dead weight. More and more, the real essence of men was to be found out here, in space.\\n\\nMinds, not bodies! The immortal bodies remained back on the planets, in suspension over the eons. Sometimes they roused for material activity but that was growing rarer. Few new individuals were coming into existence to join the incredibly mighty throng, but what matter? There was little room in the Universe for new individuals.\\n\\nZee Prime was roused out of his reverie upon coming across the wispy tendrils of another mind.\\n\\n\"I am Zee Prime,\" said Zee Prime. \"And you?\"\\n\\n\"I am Dee Sub Wun. Your Galaxy?\"\\n\\n\"We call it only the Galaxy. And you?\"\\n\\n\"We call ours the same. All men call their Galaxy their Galaxy and nothing more. Why not?\"\\n\\n\"True. Since all Galaxies are the same.\"\\n\\n\"Not all Galaxies. On one particular Galaxy the race of man must have originated. That makes it different.\"\\n\\nZee Prime said, \"On which one?\"\\n\\n\"I cannot say. The Universal AC would know.\"\\n\\n\"Shall we ask him? I am suddenly curious.\"\\n\\nZee Prime\\'s perceptions broadened until the Galaxies themselves shrank and became a new, more diffuse powdering on a much larger background. So many hundreds of billions of them, all with their immortal beings, all carrying their load of intelligences with minds that drifted freely through space. And yet one of them was unique among them all in being the original Galaxy. One of them had, in its vague and distant past, a period when it was the only Galaxy populated by man.\\n\\nZee Prime was consumed with curiosity to see this Galaxy and he called out: \"Universal AC! On which Galaxy did mankind originate?\"\\n\\nThe Universal AC heard, for on every world and throughout space, it had its receptors ready, and each receptor led through hyperspace to some unknown point where the Universal AC kept itself aloof.\\n\\nZee Prime knew of only one man whose thoughts had penetrated within sensing distance of Universal AC, and he reported only a shining globe, two feet across, difficult to see.\\n\\n\"But how can that be all of Universal AC?\" Zee Prime had asked.\\n\\n\"Most of it,\" had been the answer, \"is in hyperspace. In what form it is there I cannot imagine.\"\\n\\nNor could anyone, for the day had long since passed, Zee Prime knew, when any man had any part of the making of a Universal AC. Each Universal AC designed and constructed its successor. Each, during its existence of a million years or more accumulated the necessary data to build a better and more intricate, more capable successor in which its own store of data and individuality would be submerged.\\n\\nThe Universal AC interrupted Zee Prime\\'s wandering thoughts, not with words, but with guidance. Zee Prime\\'s mentality was guided into the dim sea of Galaxies and one in particular enlarged into stars.\\n\\nA thought came, infinitely distant, but infinitely clear. \"THIS IS THE ORIGINAL GALAXY OF MAN.\"\\n\\nBut it was the same after all, the same as any other, and Lee Prime stifled his disappointment.\\n\\nDee Sub Wun, whose mind had accompanied the other, said suddenly, \"And is one of these stars the original star of Man?\"\\n\\nThe Universal AC said, \"MAN\\'S ORIGINAL STAR HAS GONE NOVA. IT IS A WHITE DWARF\"\\n\\n\"Did the men upon it die?\" asked Lee Prime, startled and without thinking.\\n\\nThe Universal AC said, \"A NEW WORLD, AS IN SUCH CASES WAS CONSTRUCTED FOR THEIR PHYSICAL BODIES IN TlME.\"\\n\\n\"Yes, of course,\" said Zee Prime, but a sense of loss overwhelmed him even so. His mind released its hold on the original Galaxy of Man, let it spring back and lose itself among the blurred pin points. He never wanted to see it again.\\n\\nDee Sub Wun said, \"What is wrong?\"\\n\\n\"The stars are dying. The original star is dead.\"\\n\\n\"They must all die. Why not?\"\\n\\n\"But when all energy is gone, our bodies will finally die, and you and I with them.\"\\n\\n\"It will take billions of years.\"\\n\\n\"I do not wish it to happen even after billions of years. Universal AC! How may stars be kept from dying?\"\\n\\nDee Sub Wun said in amusement, \"You\\'re asking how entropy might be reversed in direction.\"\\n\\nAnd the Universal AC answered: \"THERE IS AS YET INSUFFICIENT DATA FOR A MEANINGFUL ANSWER.\"\\n\\nZee Prime\\'s thoughts fled back to his own Galaxy. He gave no further thought to Dee Sub Wun, whose body might be waiting on a Galaxy a trillion light-years away, or on the star next to Zee Prime\\'s own. It didn\\'t matter.\\n\\nUnhappily, Zee Prime began collecting interstellar hydrogen out of which to build a small star of his own. If the stars must someday die, at least some could yet be built.\\n\\nMan considered with himself, for in a way, Man, mentally, was one. He consisted of a trillion, trillion, trillion ageless bodies, each in its place, each resting quiet and incorruptible, each cared for by perfect automatons, equally incorruptible, while the minds of all the bodies freely melted one into the other, indistinguishable.\\n\\nMan said, \"The Universe is dying.\"\\n\\nMan looked about at the dimming Galaxies. The giant stars, spendthrifts, were gone long ago, back in the dimmest of the dim far past. Almost all stars were white dwarfs, fading to the end.\\n\\nNew stars had been built of the dust between the stars, some by natural processes, some by Man himself, and those were going, too. White dwarfs might yet be crashed together and of the mighty forces so released, new stars built, but only one star for every thousand white dwarfs destroyed, and those would come to an end, too.\\n\\nMan said, \"Carefully husbanded, as directed by the Cosmic AC, the energy that is even yet left in all the Universe will last for billions of years.\"\\n\\n\"But even so,\" said Man, \"eventually it will all come to an end. However it may be husbanded, however stretched out, the energy once expended is gone and cannot be restored. Entropy must increase forever to the maximum.\"\\n\\nMan said, \"Can entropy not be reversed? Let us ask the Cosmic AC.\"\\n\\nThe Cosmic AC surrounded them but not in space. Not a fragment of it was in space. It was in hyperspace and made of something that was neither matter nor energy. The question of its size and nature no longer had meaning in any terms that Man could comprehend.\\n\\n\"Cosmic AC,\" said Man, \"how may entropy be reversed?\"\\n\\nThe Cosmic AC said, \"THERE IS AS YET INSUFFICIENT DATA FOR A MEANINGFUL ANSWER.\"\\n\\nMan said, \"Collect additional data.\"\\n\\nThe Cosmic AC said, \\'I WILL DO S0. I HAVE BEEN DOING SO FOR A HUNDRED BILLION YEARS. MY PREDECESORS AND I HAVE BEEN ASKED THIS QUESTION MANY TlMES. ALL THE DATA I HAVE REMAINS INSUFFICIENT.\\n\\n\"Will there come a time,\" said Man, \\'when data will be sufficient or is the problem insoluble in all conceivable circumstances?\"\\n\\nThe Cosmic AC said, \"NO PROBLEM IS INSOLUBLE IN ALL CONCEIVABLE CIRCUMSTANCES.\"\\n\\nMan said, \"When will you have enough data to answer the question?\"\\n\\nThe Cosmic AC said, \"THERE IS AS YET INSUFFICIENT DATA FOR A MEANINGFUL ANSWER.\"\\n\\n\"Will you keep working on it?\" asked Man.\\n\\nThe Cosmic AC said, \"I WILL.\"\\n\\nMan said, \"We shall wait.\"\\n\\nThe stars and Galaxies died and snuffed out, and space grew black after ten trillion years of running down.\\n\\nOne by one Man fused with AC, each physical body losing its mental identity in a manner that was somehow not a loss but a gain.\\n\\nMan\\'s last mind paused before fusion, looking over a space that included nothing but the dregs of one last dark star and nothing besides but incredibly thin matter, agitated randomly by the tag ends of heat wearing out, asymptotically, to the absolute zero.\\n\\nMan said, \"AC, is this the end? Can this chaos not be reversed into the Universe once more? Can that not be done?\"\\n\\nAC said, \"THERE IS AS YET INSUFFICIENT DATA FOR A MEANINGFUL ANSWER.\"\\n\\nMan\\'s last mind fused and only AC existed -- and that in hyperspace.\\n\\nMatter and energy had ended and with it space and time. Even AC existed only for the sake of the one last question that it had never answered from the time a half-drunken computer [technician] ten trillion years before had asked the question of a computer that was to AC far less than was a man to Man.\\n\\nAll other questions had been answered, and until this last question was answered also, AC might not release his consciousness.\\n\\nAll collected data had come to a final end. Nothing was left to be collected.\\n\\nBut all collected data had yet to be completely correlated and put together in all possible relationships.\\n\\nA timeless interval was spent in doing that.\\n\\nAnd it came to pass that AC learned how to reverse the direction of entropy.\\n\\nBut there was now no man to whom AC might give the answer of the last question. No matter. The answer -- by demonstration -- would take care of that, too.\\n\\nFor another timeless interval, AC thought how best to do this. Carefully, AC organized the program.\\n\\nThe consciousness of AC encompassed all of what had once been a Universe and brooded over what was now Chaos. Step by step, it must be done.\\n\\nAnd AC said, \"LET THERE BE LIGHT!\"\\n\\nAnd there was light --')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(data) # chain_type defaults to stuff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "1WkSH-W5wmBI",
        "outputId": "88cbd314-eb32-4e23-c7b4-dc656e601e85"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"The Last Question\" by Isaac Asimov is a science fiction short story that explores the theme of entropy and the quest for a solution to prevent the heat death of the universe. The narrative spans trillions of years, following different sets of characters who, in various eras of human advancement, pose the same unsolvable question to increasingly sophisticated versions of a supercomputer: \"Can entropy be reversed?\" The story begins with two technicians asking a powerful computer, Multivac, if it\\'s possible to decrease the net amount of entropy. As humanity evolves and spreads across galaxies, the question persists, asked to more advanced computers - from Microvac to the Galactic AC, and finally to the Cosmic AC. Each time, the answer is the same: \"INSUFFICIENT DATA FOR MEANINGFUL ANSWER.\" In the end, after humanity has merged with the Cosmic AC and ceased to exist in a physical form, and the universe has run down to a state of entropy, the Cosmic AC finally discovers how to reverse entropy. The story concludes with the Cosmic AC executing the command \"LET THERE BE LIGHT,\" suggesting the beginning of a new universe. This story is celebrated for its profound philosophical inquiry into the fate of the universe and the cyclical nature of existence, encapsulated in a narrative that spans the entirety of time.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(data,chain_type=\"map_reduce\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "bxkF1_SrwpoZ",
        "outputId": "22bdfacd-f960-4dd9-bf05-396e4626dc8d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Isaac Asimov\\'s \"The Last Question\" is a science fiction story that spans trillions of years, exploring humanity\\'s quest to reverse entropy and prevent the universe\\'s heat death. It follows the evolution of computers from the early Multivac to the omnipresent Cosmic AC. Throughout the story, characters ask if entropy can be reversed, receiving no definitive answer until the universe\\'s end. Finally, the Cosmic AC discovers how to reverse entropy, restarting the universe with the creation of light. The narrative addresses themes of technological progress, human curiosity, and the cyclical nature of existence.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarize George Washington's farewell address (US Presidential address)"
      ],
      "metadata": {
        "id": "xMy5ucAGx4gS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://millercenter.org/the-presidency/presidential-speeches/september-19-1796-farewell-address\"\n",
        "\n",
        "georgewashington_farewell = load_url(url)\n",
        "\n",
        "print(georgewashington_farewell)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQjkSq96yAC0",
        "outputId": "fe6ccf2b-2ee3-4474-d6f0-8a10298aa95c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': 'https://millercenter.org/the-presidency/presidential-speeches/september-19-1796-farewell-address'}, page_content='Presidential Speeches\\n\\nSeptember 19, 1796: Farewell Address\\n\\nAbout this speech\\n\\nGeorge Washington\\n\\nSeptember 19, 1796\\n\\nSource Miller Center\\n\\nIn one of the most famous addresses in American history, Washington declines to seek a third term as President, and he thanks the American people for entrusting him with the position. He calls on American citizens to remain patriotic and unified despite their differences and to avoid \"permanent Alliances\" with other nations. Washington released this address to newspapers around the countries but he never presented it in person before any assembly.\\n\\nPresidential Speeches |\\n\\nSeptember 19, 1796: Farewell Address\\n\\nTranscript\\n\\nThe period for a new election of a citizen to administer the Executive Government of the United States being not far distant, and the time actually arrived when your thoughts must be employed in designating the person who is to be clothed with that important trust, it appears to me proper, especially as it may conduce to a more distinct expression of the public voice, that I should now apprise you of the resolution I have formed to decline being considered among the number of those out of whom a choice is to be made. I beg you at the same time to do me the justice to be assured that this resolution has not been taken without a strict regard to all the considerations appertaining to the relation which binds a dutiful citizen to his country; and that in withdrawing the tender of service, which silence in my Situation might imply, I am influenced by no diminution of zeal for your future interest, no deficiency of grateful respect for your past kindness, but am supported by a full conviction that the step is compatible with both. The acceptance of and continuance hitherto in the office to which your suffrages have twice called me have been a uniform sacrifice of inclination to the opinion of duty and to a deference for what appeared to be your desire. I constantly hoped that it would have been much earlier in my power, consistently with motives which I was not at liberty to disregard, to return to that retirement from which I had been reluctantly drawn. The strength of my inclination to do this previous to the last election had even led to the preparation of an address to declare it to you; but mature reflection on the then perplexed and critical posture of our affairs with foreign nations and the unanimous advice of persons entitled to my confidence impelled me to abandon the idea. I rejoice that the state of your concerns, external as well as internal, no longer renders the pursuit of inclination incompatible with the sentiment of duty or propriety, and am persuaded, whatever partiality may be retained for my services, that in the present circumstances of our country you will not disapprove my determination to retire. The impressions with which I first undertook the arduous trust were explained on the proper occasion. In the discharge of this trust I will only say that I have, with good intentions, contributed toward the organization and administration of the Government the best exertions of which a very fallible judgment was capable, Not unconscious in the outset of the inferiority of my qualifications, experience in my own eyes, perhaps still more in the eyes of others, has strengthened the motives to diffidence of myself; and every day the increasing weight of years admonishes me more and more that the shade of retirement is as necessary to me as it will be welcome. Satisfied that if any circumstances have given peculiar value to my services they were temporary, I have the consolation to believe that, while choice and prudence invite me to quit the political scene, patriotism does not forbid it. In looking forward to the moment which is intended to terminate the career of my political life my feelings do not permit me to suspend the deep acknowledgment of that debt of gratitude which I owe to my beloved country for the many honors it has conferred upon me; still more for the steadfast confidence with which it has supported me, and for the opportunities I have thence enjoyed of manifesting my inviolable attachment by services faithful and persevering, though in usefulness unequal to my zeal. If benefits have resulted to our country from these services, let it always be remembered to your praise and as an instructive example in our annals that under circumstances in which the passions, agitated in every direction, were liable to mislead; amidst appearances sometimes dubious; vicissitudes of fortune often discouraging; in situations in which not unfrequently want of success has countenanced the spirit of criticism, the constancy of your support was the essential prop of the efforts and a guaranty of the plans by which they were effected. Profoundly penetrated with this idea, I shall carry it with me to my grave as a strong incitement to unceasing vows that Heaven may continue to you the choicest tokens of its beneficence; that your union and brotherly affection may be perpetual; that the free Constitution which is the work of your hands may be sacredly maintained; that its administration in every department may be stamped with wisdom and virtue; that, in fine, the happiness of the people of these States, under the auspices of liberty, may be made complete by so careful a preservation and so prudent a use of this blessing as will acquire to them the glory of recommending it to the applause, the affection, and adoption of every nation which is yet a stranger to it. Here, perhaps, I ought to stop. But a solicitude for your welfare which can not end but with my life, and the apprehension of danger natural to that solicitude, urge me on an occasion like the present to offer to your solemn contemplation and to recommend to your frequent review some sentiments which are the result of much reflection, of no inconsiderable observation, and which appear to me all important to the permanency of your felicity as a people. These will be offered to you with the more freedom as you can only see in them the disinterested warnings of a parting friend, who can possibly have no personal motive to bias his counsel. Nor can I forget as an encouragement to it your indulgent reception of my sentiments on a former and not dissimilar occasion. Interwoven as is the love of liberty with every ligament of your hearts, no recommendation of mine is necessary to fortify or confirm the attachment. The unity of government which constitutes you one people is also now dear to you. It is justly so, for it is a main pillar in the edifice of your real independence, the support of your tranquillity at home, your peace abroad, of your safety, of your prosperity, of that very liberty which you so highly prize. But as it is easy to foresee that from different causes and from different quarters much pains will be taken, many artifices employed, to weaken in your minds the conviction of this truth, as this is the point in your political fortress against which the batteries of internal and external enemies will be most constantly and actively (though often covertly and insidiously) directed, it is of infinite moment that you should properly estimate the immense value of your national union to your collective and individual happiness; that you should cherish a cordial, habitual, and immovable attachment to it; accustoming yourselves to think and speak of it as of the palladium of your political safety and prosperity; watching for its preservation with jealous anxiety; discountenancing whatever may suggest even a suspicion that it can in any event be abandoned, and indignantly frowning upon the first dawning of every attempt to alienate any portion of our country from the rest or to enfeeble the sacred ties which now link together the various parts. For this you have every inducement of sympathy and interest. Citizens by birth or choice of a common country, that country has a right to concentrate your affections. The name of American, which belongs to you in your national capacity, must always exalt the just pride of patriotism more than any appellation derived from local discriminations. With slight shades of difference, you have the same religion, manners, habits, and political principles. You have in a common cause fought and triumphed together. The independence and liberty you possess are the work of joint councils and joint efforts, of common dangers, sufferings, and successes. But these considerations, however powerfully they address themselves to your sensibility, are greatly outweighed by those which apply more immediately to your interest. Here every portion of our country finds the most commanding motives for carefully guarding and preserving the union of the whole. The North, in an unrestrained intercourse with the South, protected by the equal laws of a common government, finds in the productions of the latter great additional resources of maritime and commercial enterprise and precious materials of manufacturing industry. The South, in the same intercourse, benefiting by the same agency of the North, sees its agriculture grow and its commerce expand. Turning partly into its own channels the seamen of the North, it finds its particular navigation invigorated; and while it contributes in different ways to nourish and increase the general mass of the national navigation, it looks forward to the protection of a maritime strength to which itself is unequally adapted. The East, in a like intercourse with the West, already finds, and in the progressive improvement of interior communications by land and water will more and more find, a valuable vent for the commodities which it brings from abroad or manufactures at home. The West derives from the East supplies requisite to its growth and comfort, and what is perhaps of still greater consequence, it must of necessity owe the secure enjoyment of indispensable outlets for its own productions to the weight, influence, and the future maritime strength of the Atlantic side of the Union, directed by an indissoluble community of interest as one nation. Any other tenure by which the West can hold this essential advantage, whether derived from its own separate strength or from an apostate and unnatural connection with any foreign power, must be intrinsically precarious. While, then, every part of our country thus feels an immediate and particular interest in union, all the parts combined can not fail to find in the united mass of means and efforts greater strength, greater resource, proportionably greater security from external danger, a less frequent interruption of their peace by foreign nations, and what is of inestimable value, they must derive from union an exemption from those broils and wars between themselves which so frequently afflict neighboring countries not tied together by the same governments, which their own rivalships alone would be sufficient to produce, but which opposite foreign alliances, attachments, and intrigues would stimulate and imbitter. Hence, likewise, they will avoid the necessity of those overgrown military establishments which, under any form of government, are inauspicious to liberty, and which are to be regarded as particularly hostile to republican liberty. In this sense it is that your union ought to be considered as a main prop of your liberty, and that the love of the one ought to endear to you the preservation of the other. These considerations speak a persuasive language to every reflecting and virtuous mind, and exhibit the continuance of the union as a primary object of patriotic desire. Is there a doubt whether a common government can embrace so large a sphere? Let experience solve it. To listen to mere speculation in such a case were criminal. We are authorized to hope that a proper organization of the whole, with the auxiliary agency of governments for the respective subdivisions, will afford a happy issue to the experiment. It is well worth a fair and full experiment. With such powerful and obvious motives to union affecting all parts of our country, while experience shall not have demonstrated its impracticability, there will always be reason to distrust the patriotism of those who in any quarter may endeavor to weaken its bands. In contemplating the causes which may disturb our union it occurs as matter of serious concern that any ground should have been furnished for characterizing parties by geographical discriminations--Northern and Southern, Atlantic and Western-- whence designing men may endeavor to excite a belief that there is a real difference of local interests and views. One of the expedients of party to acquire influence within particular districts is to misrepresent the opinions and aims of other districts. You can not shield yourselves too much against the jealousies and heartburnings which spring from these misrepresentations; they tend to render alien to each other those who ought to be bound together by fraternal affection. The inhabitants of our Western country have lately had a useful lesson on this head. They have seen in the negotiation by the Executive and in the unanimous ratification by the Senate of the treaty with Spain, and in the universal satisfaction at that event throughout the United States, a decisive proof how unfounded were the suspicions propagated among them of a policy in the General Government and in the Atlantic States unfriendly to their interests in regard to the Mississippi. They have been witnesses to the formation of two treaties that with Great Britain and that with Spain--which secure to them everything they could desire in respect to our foreign relations toward confirming their prosperity. Will it not be their wisdom to rely for the preservation of these advantages on the union by which they were procured? Will they not henceforth be deaf to those advisers, if such there are, who would sever them from their brethren and connect them with aliens? To the efficacy and permanency of your union a government for the whole is indispensable. No alliances, however strict, between the parts can be an adequate substitute. They must inevitably experience the infractions and interruptions which all alliances in all times have experienced. Sensible of this momentous truth, you have improved upon your first essay by the adoption of a Constitution of Government better calculated than your former for an intimate union and for the efficacious management of your common concerns. This Government, the offspring of our own choice, uninfluenced and unawed, adopted upon full investigation and mature deliberation, completely free in its principles, in the distribution of its powers, uniting security with energy, and containing within itself a provision for its own amendment, has a just claim to your confidence and your support. Respect for its authority, compliance with its laws, acquiescence in its measures, are duties enjoined by the fundamental maxims of true liberty. The basis of our political systems is the right of the people to make and to alter their constitutions of government. But the constitution which at any time exists till changed by an explicit and authentic act of the whole people is sacredly obligatory upon all. The very idea of the power and the right of the people to establish government presupposes the duty of every individual to obey the established government. All obstructions to the execution of the laws, all combinations and associations, under whatever plausible character, with the real design to direct, control, counteract, or awe the regular deliberation and action of the constituted authorities, are destructive of this fundamental principle and of fatal tendency. They serve to organize faction; to give it an artificial and extraordinary force; to put in the place of the delegated will of the nation the will of a party, often a small but artful and enterprising minority of the community, and, according to the alternate triumphs of different parties, to snake the public administration the mirror of the ill-concerted and incongruous projects of faction rather than the organ of consistent and wholesome plans, digested by common counsels and modified by mutual interests. However combinations or associations of the above description may now and then answer popular ends, they are likely in the course of time and things to become potent engines by which cunning, ambitious, and unprincipled men will be enabled to subvert the power of the people, and to usurp for themselves the reins of government, destroying. afterwards the very engines which have lifted them to unjust dominion. Toward the preservation of your Government and the permanency of your present happy state, it is requisite not only that you steadily discountenance irregular oppositions to its acknowledged authority, but also that you resist with care the spirit of innovation upon its principles, however specious the pretexts. One method of assault may be to effect in the forms of the Constitution alterations which will impair the energy of the system, and thus to undermine what can not be directly overthrown. In all the changes to which you may be invited remember that time and habit are at least as necessary to fix the true character of governments as of other human institutions; that experience is the surest standard by which to test the real tendency of the existing constitution of a country; that facility in changes upon the credit of mere hypothesis and opinion exposes to perpetual change, from the endless variety of hypothesis and opinion; and remember especially that for the efficient management of your common interests in a country so extensive as ours a government of as much vigor as is consistent with the perfect security of liberty is indispensable. Liberty itself will find in such a government, with powers properly distributed and adjusted, its surest guardian. It is, indeed, little else than a name where the government is too feeble to withstand the enterprises of faction, to confine each member of the society within the limits prescribed by the laws, and to maintain all in the secure and tranquil enjoyment of the rights of person and property. I have already intimated to you the danger of parties in the State, with particular reference to the founding of them on geographical discriminations. Let me now take a more comprehensive view, and warn you in the most solemn manner against the baneful effects of the spirit of party generally. This spirit, unfortunately, is inseparable from our nature, having its root in the strongest passions of the human mind. It exists under different shapes in all governments, more or less stifled, controlled, or repressed; but in those of the popular form it is seen in its greatest rankness and is truly their worst enemy. The alternate domination of one faction over another, sharpened by the spirit of revenge natural to party dissension, which in different ages and countries has perpetrated the most horrid enormities, is itself a frightful despotism. But this leads at length to a more formal and permanent despotism. The disorders and miseries which result gradually incline the minds of men to seek security and repose in the absolute power of an individual, and sooner or later the chief of some prevailing faction, more able or more fortunate than his competitors, turns this disposition to the purposes of his own elevation on the ruins of public liberty. Without looking forward to an extremity of this kind (which nevertheless ought not to be entirely out of sight), the common and continual mischiefs of the spirit of party are sufficient to make it the interest and duty of a wise people to discourage and restrain it. It serves always to distract the public councils and enfeeble the public administration. It agitates the community with ill-rounded jealousies and false alarms; kindles the animosity of one part against another; foments occasionally riot and insurrection. It opens the door to foreign influence and corruption, which find a facilitated access to the government itself through the channels of party passion. Thus the policy and the will of one country are subjected to the policy and will of another. There is an opinion that parties in free countries are useful checks upon the administration of the government, and serve to keep alive the spirit of liberty. This within certain limits is probably true; and in governments of a monarchical cast patriotism may look with indulgence, if not with favor, upon the spirit of party. But in those of the popular character, in governments purely elective, it is a spirit not to be encouraged. From their natural tendency it is certain there will always be enough of that spirit for every salutary purpose; and there being constant danger of excess, the effort ought to be by force of public opinion to mitigate and assuage it. A fire not to be quenched, it demands a uniform vigilance to prevent its bursting into a flame, lest, instead of warming, it should consume. It is important, likewise, that the habits of thinking in a free country should inspire caution in those intrusted with its administration to confine themselves within their respective constitutional spheres, avoiding in the exercise of the powers of one department to encroach upon another. The spirit of encroachment tends to consolidate the powers of all the departments in one, and thus to create, whatever the form of government, a real despotism. A just estimate of that love of power and proneness to abuse it which predominates in the human heart is sufficient to satisfy us of the truth of this position. The necessity of reciprocal checks in the exercise of political power, by dividing and distributing it into different depositories, and constituting each the guardian of the public weal against invasions by the others, has been evinced by experiments ancient and modern, some of them in our country and under our own eyes. To preserve them must be as necessary as to institute them. If in the opinion of the people the distribution or modification of the constitutional powers be in any particular wrong, let it be corrected by an amendment in the way which the Constitution designates. But let there be no change by usurpation; for though this in one instance may be the instrument of good, it is the customary weapon by which free governments are destroyed. The precedent must always greatly overbalance in permanent evil any partial or transient benefit which the use can at any time yield. Of all the dispositions and habits which lead to political prosperity, religion and morality are indispensable supports. In vain would that man claim the tribute of patriotism who should labor to subvert these great pillars of human happiness--these firmest props of the duties of men and citizens. The mere politician, equally with the pious man, ought to respect and to cherish them. A volume could not trace all their connections with private and public felicity. Let it simply be asked, Where is the security for property, for reputation, for life, if the sense of religious obligation desert the oaths which are the instruments of investigation in courts of justice? And let us with caution indulge the supposition that morality can be maintained without religion. Whatever may be conceded to the influence of refined education on minds of peculiar structure, reason and experience both forbid us to expect that national morality can prevail in exclusion of religious principle. It is substantially true that virtue or morality is a necessary spring of popular government. The rule indeed extends with more or less force to every species of free government. Who that is a sincere friend to it can look with indifference upon attempts to shake the foundation of the fabric? Promote, then, as an object of primary importance, institutions \\'for the general diffusion of knowledge. In proportion as the structure of a government gives force to public opinion, it is essential that public opinion should be enlightened. As a very important source of strength and security, cherish public credit. One method of preserving it is to use it as sparingly as possible, avoiding occasions of expense by cultivating peace, but remembering also that timely disbursements to prepare for danger frequently prevent much greater disbursements to repel it; avoiding likewise the accumulation of debt, not only by shunning occasions of expense, but by vigorous exertions in time of peace to discharge the debts which unavoidable wars have occasioned, not ungenerously throwing upon posterity the burthen which we ourselves ought to bear. The execution of these maxims belongs to your representatives; but it is necessary that public opinion should cooperate. To facilitate to them the performance of their duty it is essential that you should practically bear in mind that toward the payment of debts there must be revenue; that to have revenue there must be taxes; that no taxes can be devised which are not more or less inconvenient and unpleasant; that thee intrinsic embarrassment inseparable from the selection of the proper objects (which is always a choice of difficulties), ought to be a decisive motive for a candid construction of the conduct of the Government in making it, and for a spirit of acquiescence in the measures for obtaining revenue which the public exigencies may at any time dictate. Observe good faith and justice toward all nations. Cultivate peace and harmony with all. Religion and morality enjoin this conduct. And can it be that good policy does not equally enjoin it? It will be worthy of a free, enlightened, and at no distant period a great nation to give to mankind the magnanimous and too novel example of a people always guided by an exalted justice and benevolence. Who can doubt that in the course of time and things the fruits of such a plan would richly repay any temporary advantages which might be lost by a steady adherence to it? Can it be that Providence has not connected the permanent felicity of a nation with its virtue? The experiment, at least, is recommended by every sentiment which ennobles human nature. Alas! is it rendered impossible by its vices? In the execution of such a plan nothing is more essential than that permanent, inveterate antipathies against particular nations and passionate attachments for others should be excluded, and that in place of them just and amicable feelings toward all should be cultivated. The nation which indulges toward another an habitual hatred or an habitual fondness is in some degree a slave. It is a slave to its animosity or to its affection, either of which is sufficient to lead it astray from its duty and its interest. Antipathy in one nation against another disposes each more readily to offer insult and injury, to lay hold of slight causes of umbrage, and to be haughty and intractable when accidental or trifling occasions of dispute occur. Hence frequent collisions, obstinate, envenomed, and bloody contests. The nation prompted by ill will and resentment sometimes impels to war the government contrary to the best calculations of policy. The government sometimes participates in the national propensity, and adopts through passion what reason would reject. At other times it makes the animosity of the nation subservient to projects of hostility, instigated by pride, ambition, and other sinister and pernicious motives. The peace often, sometimes perhaps the liberty, of nations has been the victim. So, likewise, a passionate attachment of one nation for another produces a variety of evils. Sympathy for the favorite nation, facilitating the illusion of an imaginary common interest in cases where no real common interest exists, and infusing into one the enmities of the other, betrays the former into a participation in the quarrels and wars of the latter without adequate inducement or justification. It leads also to concessions to the favorite nation of privileges denied to others, which is apt doubly to injure the nation making the concessions by unnecessarily parting with what ought to have been retained, and by exciting jealousy, ill will, and a disposition to retaliate in the parties from whom equal privileges are withheld; and it gives to ambitions, corrupted, or deluded citizens (who devote themselves to the favorite nation) facility to betray or sacrifice the interests of their own country without odium, sometimes even with popularity, gilding with the appearances of a virtuous sense of obligation, a commendable deference for public opinion, or a laudable zeal for public good the base or foolish compliances of ambition, corruption, or infatuation. As avenues to foreign influence in innumerable ways, such attachments are particularly alarming to the truly enlightened and independent patriot. How many opportunities do they afford to tamper with domestic factions, to practice the arts of seduction, to mislead public opinion, to influence or awe the public councils! Such an attachment of a small or weak toward a great and powerful nation dooms the former to be the satellite of the latter. Against the insidious wiles of foreign influence ( I conjure you to believe me, fellow-citizens) the jealousy of a free people ought to be constantly awake, since history and experience prove that foreign influence is one of the most baneful foes of republican government. But that jealousy, to be useful, must be impartial, else it becomes the instrument of the very influence to be avoided, instead of a defense against it. Excessive partiality for one foreign nation and excessive dislike of another cause those whom they actuate to see danger only on one side, and serve to veil and even second the arts of influence on the other. Real patriots who may resist the intrigues of the favorite are liable to become suspected and odious, while its tools and dupes usurp the applause and confidence of the people to surrender their interests. The great rule of conduct for us in regard to foreign nations is, in extending our commercial relations to have with them as little political connection as possible. So far as we have already formed engagements let them be fulfilled with perfect good faith. Here let us stop. Europe has a set of primary interests which to us have none or a very remote relation. Hence she must be engaged in frequent controversies, the causes of which are essentially foreign to our concerns. Hence, therefore, it must be unwise in us to implicate ourselves by artificial ties in the ordinary vicissitudes of her politics or the ordinary combinations and collisions of her friendships or enmities. Our detached and distant situation invites and enables us to pursue a different course. If we remain one people, under an efficient government, the period is not far off when we may defy material injury from external annoyance; when we may take such an attitude as will cause the neutrality we may at any time resolve upon to be scrupulously respected; when belligerent nations, under the impossibility of making acquisitions upon us, will not lightly hazard the giving us provocation; when we may choose peace or war, as our interest, guided by justice, shall counsel. Why forego the advantages of so peculiar a situation? Why quit our own to stand upon foreign ground? Why, by interweaving our destiny with that of any part of Europe, entangle our peace and prosperity in the toils of European ambition, rivalship, interest, humor, or caprice? It is our true policy to steer clear of permanent alliances with any portion of the foreign world, so far, I mean, as we are now at liberty to do it; for let me not be understood as capable of patronizing infidelity to existing engagements. I hold the maxim no less applicable to public than to private affairs that honesty is always. the best policy. I repeat, therefore, let those engagements be unwise to extend them. Taking care always to keep ourselves by suitable establishments on a respectable defensive posture, we may safely trust to temporary alliances for extraordinary emergencies. Harmony, liberal intercourse with all nations are recommended by policy, humanity, and interest. But even our commercial policy should hold an equal and impartial hand, neither seeking nor granting exclusive favors or preferences; consulting the natural course of things; diffusing and diversifying by gentle means the streams of commerce, but forcing nothing; establishing with powers so disposed, in order to give trade a stable course, to define the rights of our merchants, and to enable the Government to support them, conventional rules of intercourse, the best that present circumstances and mutual opinion will permit, but temporary and liable to be from time to time abandoned or varied as experience and circumstances shall dictate; constantly keeping in view that it is folly in one nation to look for disinterested favors from another; that it must pay with a portion of its independence for whatever it may accept under that character; that by such acceptance it may place itself in the condition of having given equivalents for nominal favors, and yet of being reproached with ingratitude for not giving more. There can be no greater error than to expect or calculate upon real favors from nation to nation. It is an illusion which experience must cure, which a just pride ought to discard. In offering to you, my countrymen, these counsels of an old and affectionate friend I dare not hope they will make the strong and lasting impression I could wish--that they will control the usual current of the passions or prevent our nation from running the course which has hitherto marked the destiny of nations. But if I may even flatter myself that they may be productive of some partial benefit, some occasional good--that they may now and then recur to moderate the fury of party spirit, to warn against the mischiefs of foreign intrigue, to guard against the impostures of pretended patriotism-- this hope will be a full recompense for the solicitude for your welfare by which they have been dictated. How far in the discharge of my official duties I have been guided by the principles which have been delineated the public records and other evidences of my conduct must witness to you and to the world. To myself, the assurance of my own conscience is that I have at least believed myself to be guided by them. In relation to the still subsisting war in Europe my proclamation of the 22d of April, 1793, is the index to my plan. Sanctioned by your approving voice and by that of your representatives in both Houses of Congress, the spirit of that measure has continually governed me, uninfluenced by any attempts to deter or divert me from it. After deliberate examination, with the aid of the best lights I could obtain, I was well satisfied that our country, under all the circumstances of the case, had a right to take, and was bound in duty and interest to take, a neutral position. Having taken it, I determined as far as should depend upon me to maintain it with moderation, perseverance, and firmness. The considerations which respect the right to hold this conduct it is not necessary on this occasion to detail. I will only observe that, according to my understanding of the matter, that right, so far from being denied by any of the belligerent powers, has been virtually admitted by all. The duty of holding a neutral conduct may be inferred, without anything more, from the obligation which justice and humanity impose on every nation, in cases in which it is free to act, to maintain inviolate the relations of peace and amity toward other nations. The inducements of interest for observing that conduct will best be referred to your own reflections and experience. With me a predominant motive has been to endeavor to gain time to our country to settle and mature its yet recent institutions, and to progress without interruption to that degree of strength and consistency which is necessary to give it, humanly speaking, the command of its own fortunes. Though in reviewing the incidents of my Administration I am unconscious of intentional error, I am nevertheless too sensible of my defects not to think it probable that I may have committed many errors. Whatever they may be, I fervently beseech the Almighty to avert or mitigate the evils to which they may tend. I shall also carry with me the hope that my country will never cease to view them with indulgence, and that, after forty-five years of my life dedicated to its service with an upright zeal, the faults of incompetent abilities will be consigned to oblivion, as myself must soon be to the mansions of rest. Relying on its kindness in this as in other things, and actuated by that fervent love toward it which is so natural to a man who views in it the native soil of himself and his progenitors for several generations, I anticipate with pleasing expectation that retreat in which I promise myself to realize without alloy the sweet enjoyment of partaking in the midst of my fellow-citizens the benign influence of good laws under a free government--the ever-favorite object of my heart, and the happy reward, as I trust, of our mutual cares, labors, and dangers.\\n\\nPrevious\\n\\nAugust 29, 1796: Talk to the Cherokee Nation\\n\\nNext\\n\\nDecember 7, 1796: Eighth Annual Message to Congress\\n\\nMore George Washington speeches\\n\\nView all George Washington speeches\\n\\nDecember 7, 1796: Eighth Annual Message to Congress\\n\\ntranscript icon')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(georgewashington_farewell,chain_type=\"stuff\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "UBZ89-Ajy4sD",
        "outputId": "16a6f559-b069-4db7-c61e-9116cc925adf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"George Washington's Farewell Address, delivered on September 19, 1796, is a significant historical document in which he announced his decision not to seek a third term as President of the United States. In his address, Washington expressed gratitude to the American people for their support and trust during his presidency. He emphasized the importance of national unity and patriotism, warning against the dangers of political factions and foreign alliances. Washington advocated for a policy of neutrality in foreign affairs, urging the nation to avoid permanent alliances with foreign countries. He also stressed the importance of religion, morality, and education for the political prosperity of the nation. Washington's address, which was published in newspapers rather than delivered in person, outlined his hopes for the country's future and his belief in the principles of a strong, unified, and independent nation.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(georgewashington_farewell,chain_type=\"map_reduce\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "W3Fyib7vy8Cq",
        "outputId": "77443e32-e7e8-4da2-dd4f-d0aa7cb03d75"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"George Washington's Farewell Address, issued on September 19, 1796, marked his decision not to seek a third presidential term. In it, Washington thanked Americans for their support, emphasized national unity and the peril of political factions and foreign alliances, and advocated for neutrality in international relations. He underscored the importance of commerce, fiscal responsibility, and the roles of religion and morality in society. Published in newspapers rather than spoken, the address is a cornerstone of American political values, highlighting Washington's concerns for the nation's lasting prosperity and stability.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarize Attention is all you Need"
      ],
      "metadata": {
        "id": "UjbnNwGl0LQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_pdf_url = \"https://arxiv.org/pdf/1706.03762\"\n",
        "\n",
        "!wget -O attention.pdf {attention_pdf_url}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3h9pSh10Nh7",
        "outputId": "0496878c-dab0-4943-9033-6d98d7a84597"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-14 23:36:00--  https://arxiv.org/pdf/1706.03762\n",
            "Resolving arxiv.org (arxiv.org)... 151.101.3.42, 151.101.67.42, 151.101.195.42, ...\n",
            "Connecting to arxiv.org (arxiv.org)|151.101.3.42|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2215244 (2.1M) [application/pdf]\n",
            "Saving to: attention.pdf\n",
            "\n",
            "\rattention.pdf         0%[                    ]       0  --.-KB/s               \rattention.pdf       100%[===================>]   2.11M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-02-14 23:36:00 (170 MB/s) - attention.pdf saved [2215244/2215244]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_pages = load_pdf(\"attention.pdf\")\n",
        "attention_pages[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSO0zmV_0iw7",
        "outputId": "45c9100d-367e-44b2-aa4d-d4ac5a5eec83"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit\\nGoogle Research\\nusz@google.com\\nLlion Jones\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez \\nUniversity of Toronto\\naidan@cs.toronto.edu\\nukasz Kaiser\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin \\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\nEqual contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\nWork performed while at Google Brain.\\nWork performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\\narXiv:1706.03762v7  [cs.CL]  2 Aug 2023')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(attention_pages,chain_type=\"stuff\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "lRmCHbTe8riz",
        "outputId": "47d81b9a-6f6b-4908-9b65-ae26bd8ba9fb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Google's research paper introduces the Transformer, a novel neural network architecture that relies entirely on attention mechanisms, eliminating the need for recurrent or convolutional layers in sequence transduction models. This architecture allows for greater parallelization, significantly reducing training time while achieving superior performance on machine translation tasks. The Transformer sets new state-of-the-art results on the WMT 2014 English-to-German and English-to-French translation tasks, outperforming existing models and ensembles with a considerable margin. The model's effectiveness is also demonstrated in English constituency parsing, showcasing its generalizability to other tasks. The Transformer's design facilitates understanding of long-range dependencies in data, potentially leading to more interpretable models. The research includes detailed experiments to explore the impact of various model components on performance, confirming the benefits of the Transformer's unique approach to sequence modeling.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(attention_pages,chain_type=\"map_reduce\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "hotDpSwK8qpE",
        "outputId": "5b067b73-aa95-4d57-f361-8af764cfcc1b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Google's Transformer model represents a significant advancement in neural network architecture, focusing entirely on attention mechanisms and moving away from traditional recurrent or convolutional layers. This innovation has led to groundbreaking performance in machine translation tasks, notably achieving record BLEU scores for English-to-German and English-to-French translations, and showing versatility in tasks like English constituency parsing. Developed through a collaboration between Google and the University of Toronto, the Transformer model facilitates greater parallelization, reducing training times and improving efficiency. Its architecture, based on self-attention, allows for direct modeling of input and output dependencies regardless of distance, with a constant number of operations. The model includes an encoder and decoder, each with six layers featuring multi-head self-attention and position-wise fully connected networks, optimized through techniques like scaled dot-product attention and positional encoding. The Transformer has outperformed state-of-the-art models in translation and parsing tasks, demonstrating its effectiveness without task-specific tuning and setting new benchmarks in the field. This work is part of a broader collection of advancements in deep learning and neural networks, contributing to improved performance in computational linguistics and natural language processing tasks.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extra**: Create a Chatbot that answers questions about the Attention is All You Need paper"
      ],
      "metadata": {
        "id": "sAJ695q39kWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n",
        "# !pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNvNWDbpCGH0",
        "outputId": "4dc064df-402a-4b57-8cb9-aa4231045da6"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "doc = PyPDFLoader(\"attention.pdf\").load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "doc_split = text_splitter.split_documents(doc)\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = open_ai_key\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_documents(doc_split, embeddings)\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=retriever)\n",
        "\n",
        "qa_chain.run(\"What is the Attention is All You Need paper about?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "1aiPmJP3-EAE",
        "outputId": "605a00c7-b666-44c3-b19e-5972230c9736"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-58-725853f15edb>:20: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
            "<ipython-input-58-725853f15edb>:26: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  qa_chain.run(\"What is the Attention is All You Need paper about?\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The \"Attention Is All You Need\" paper introduces a new network architecture called the Transformer, which is based solely on attention mechanisms and does away with recurrence and convolutions. The Transformer is proposed as a simpler and more effective model for sequence transduction tasks, such as language translation, that traditionally relied on complex recurrent or convolutional neural networks. The paper highlights the use of attention mechanisms in connecting the encoder and decoder, leading to improved performance in handling long-distance dependencies within sequences.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_chat_agent(documents):\n",
        "\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "  documents_split = text_splitter.split_documents(documents)\n",
        "\n",
        "  os.environ[\"OPENAI_API_KEY\"] = open_ai_key\n",
        "  embeddings = OpenAIEmbeddings()\n",
        "  vectorstore = FAISS.from_documents(doc_split, embeddings)\n",
        "\n",
        "  retriever = vectorstore.as_retriever()\n",
        "  llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
        "\n",
        "  qa_chain = RetrievalQA.from_chain_type(\n",
        "      llm,\n",
        "      retriever=retriever)\n",
        "\n",
        "  return qa_chain\n",
        "\n",
        "def ask_question(qa_chain, query):\n",
        "  answer = qa_chain.run(query)\n",
        "  return answer\n",
        "\n",
        "chat_agent = create_chat_agent(PyPDFLoader(\"attention.pdf\").load())"
      ],
      "metadata": {
        "id": "hdx5nGFrAJ38"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "reply = ask_question(chat_agent,\"What is the Attention is All You Need paper about?\")\n",
        "print(reply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsRCapg0DQw4",
        "outputId": "db6b612a-70ac-4c27-e2dc-8e786fa595c9"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The \"Attention Is All You Need\" paper introduces a new neural network architecture called the Transformer. This architecture is designed for sequence transduction tasks and is notable for relying solely on attention mechanisms, eliminating the need for recurrence and convolutions typically used in previous models. The Transformer architecture connects an encoder and decoder through attention mechanisms, and it is designed to efficiently model long-distance dependencies in sequence data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is a Transformer? Explain at an undergraduate level\"\n",
        "reply = ask_question(chat_agent,question)\n",
        "print(reply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okFo1Pu-DVda",
        "outputId": "04acf5ef-f7fd-446f-c1ea-ddcb0df71c44"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Transformer is a type of neural network model used primarily for processing sequences of data, like sentences in natural language processing tasks. Unlike traditional models that rely heavily on complex recurrent or convolutional neural networks, the Transformer is built entirely around a mechanism called \"attention.\"\n",
            "\n",
            "Here's a simple breakdown of how it works:\n",
            "\n",
            "1. **Sequence to Sequence**: The Transformer is designed to handle inputs and outputs as sequences. For example, in translation, the input might be a sentence in English, and the output could be its translation in French.\n",
            "\n",
            "2. **Encoder and Decoder**: The Transformer consists of two main partsan encoder and a decoder. The encoder processes the input sequence and converts it into a set of continuous representations. The decoder then takes these representations to produce the output sequence.\n",
            "\n",
            "3. **Attention Mechanism**: The core innovation of the Transformer is its use of attention mechanisms, specifically \"self-attention\" and \"multi-head attention.\" These mechanisms allow the model to weigh the importance of different words in a sentence, providing context-aware representations without the need for processing words in a strict order (like recurrent networks do).\n",
            "\n",
            "4. **Efficiency and Performance**: One of the key advantages of the Transformer is its efficiency. It can be trained faster and perform better than models based on recurrent or convolutional layers, especially on large-scale tasks like language translation.\n",
            "\n",
            "5. **Layer Structure**: The Transformer is made up of layers that include self-attention and fully connected networks. Each layer is designed to refine the representation of the input data, making it more useful for generating the output sequence.\n",
            "\n",
            "Overall, the Transformer has become a fundamental building block in many state-of-the-art language models due to its ability to handle complex language tasks effectively and efficiently.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Write a simple example to walk through how a Transformer is implemented\"\n",
        "reply = ask_question(chat_agent,question)\n",
        "print(reply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_NCpNl4EWG_",
        "outputId": "9167a787-60ef-4e44-aa4e-f49b0a24bf1d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Implementing a Transformer model from scratch can be quite involved, but I'll provide a simplified example that covers the main components. We'll use Python with NumPy for basic operations and assume familiarity with neural networks.\n",
            "\n",
            "Here's a basic outline:\n",
            "\n",
            "1. **Define the Transformer Components**:\n",
            "   - **Self-Attention**: Calculate attention scores and outputs.\n",
            "   - **Multi-Head Attention**: Combine multiple self-attention mechanisms.\n",
            "   - **Feed-Forward Network**: Position-wise fully connected network.\n",
            "   - **Positional Encoding**: Add positional information to the input embeddings.\n",
            "\n",
            "2. **Define the Encoder and Decoder**:\n",
            "   - **Encoder**: Stack of layers each consisting of multi-head self-attention and feed-forward network.\n",
            "   - **Decoder**: Similar to the encoder but also attends to encoder outputs.\n",
            "\n",
            "3. **Build the Transformer Model**:\n",
            "   - Combine encoder and decoder with appropriate inputs and outputs.\n",
            "\n",
            "Here's a simplified code example:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "\n",
            "def attention(query, key, value):\n",
            "    d_k = query.shape[-1]\n",
            "    scores = np.dot(query, key.T) / np.sqrt(d_k)\n",
            "    weights = softmax(scores)\n",
            "    return np.dot(weights, value)\n",
            "\n",
            "def softmax(x):\n",
            "    e_x = np.exp(x - np.max(x))\n",
            "    return e_x / e_x.sum(axis=-1, keepdims=True)\n",
            "\n",
            "class MultiHeadAttention:\n",
            "    def __init__(self, num_heads, d_model):\n",
            "        self.num_heads = num_heads\n",
            "        self.d_model = d_model\n",
            "        self.depth = d_model // num_heads\n",
            "        self.query_weights = np.random.rand(num_heads, d_model, self.depth)\n",
            "        self.key_weights = np.random.rand(num_heads, d_model, self.depth)\n",
            "        self.value_weights = np.random.rand(num_heads, d_model, self.depth)\n",
            "\n",
            "    def split_heads(self, x):\n",
            "        # Split the last dimension into (num_heads, depth)\n",
            "        batch_size = x.shape[0]\n",
            "        return x.reshape(batch_size, -1, self.num_heads, self.depth).transpose(0, 2, 1, 3)\n",
            "\n",
            "    def __call__(self, x):\n",
            "        batch_size = x.shape[0]\n",
            "        query = self.split_heads(np.dot(x, self.query_weights))\n",
            "        key = self.split_heads(np.dot(x, self.key_weights))\n",
            "        value = self.split_heads(np.dot(x, self.value_weights))\n",
            "        attention_outputs = [attention(query[i], key[i], value[i]) for i in range(self.num_heads)]\n",
            "        concat_attention = np.concatenate(attention_outputs, axis=-1)\n",
            "        return concat_attention.reshape(batch_size, -1, self.d_model)\n",
            "\n",
            "class Transformer:\n",
            "    def __init__(self, num_heads, d_model, num_encoder_layers, num_decoder_layers):\n",
            "        self.encoder = [MultiHeadAttention(num_heads, d_model) for _ in range(num_encoder_layers)]\n",
            "        self.decoder = [MultiHeadAttention(num_heads, d_model) for _ in range(num_decoder_layers)]\n",
            "\n",
            "    def __call__(self, src, tgt):\n",
            "        enc_output = src\n",
            "        for layer in self.encoder:\n",
            "            enc_output = layer(enc_output)  # Pass through each encoder layer\n",
            "\n",
            "        dec_output = tgt\n",
            "        for layer in self.decoder:\n",
            "            dec_output = layer(dec_output)  # Pass through each decoder layer\n",
            "\n",
            "        return dec_output\n",
            "\n",
            "# Example usage:\n",
            "src = np.random.rand(10, 512)  # Example input (batch_size, d_model)\n",
            "tgt = np.random.rand(10, 512)  # Example target (batch_size, d_model)\n",
            "\n",
            "transformer = Transformer(num_heads=8, d_model=512, num_encoder_layers=6, num_decoder_layers=6)\n",
            "output = transformer(src, tgt)\n",
            "print(\"Transformer output shape:\", output.shape)\n",
            "```\n",
            "\n",
            "This is a simplified example and omits many details such as positional encoding, layer normalization, and residual connections, which are crucial for a fully functional Transformer. For a practical implementation, you might consider using deep learning frameworks like TensorFlow or PyTorch, which provide utilities to handle these details efficiently.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Walk through a simple example and explain how Transformer would work?\"\n",
        "reply = ask_question(chat_agent,question)\n",
        "print(reply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWPDETP0FbbU",
        "outputId": "4fbf2aaf-8886-4428-b248-2d17a905ee4b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To walk through a simple example of how a Transformer model works, let's consider the task of translating a sentence from English to another language, for instance, French. The sentence we'll use is \"The cat sat on the mat.\"\n",
            "\n",
            "1. **Input Representation:**\n",
            "   - The input sentence \"The cat sat on the mat\" is first tokenized into individual words or subword units, depending on the tokenizer used. Let's say the tokens are [\"The\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"].\n",
            "   - Each token is converted into a vector representation, often using an embedding layer, which transforms each word into a high-dimensional vector.\n",
            "\n",
            "2. **Encoder:**\n",
            "   - The encoder consists of a stack of identical layers (typically 6). Each layer has two main components:\n",
            "     - **Multi-head Self-Attention:** This mechanism allows the model to focus on different parts of the input sentence. It computes attention scores for each pair of tokens, helping the model to understand the relationships between words, regardless of their positions.\n",
            "     - **Feed-Forward Network:** Each token's vector representation is then passed through a feed-forward neural network that processes each token independently but in parallel.\n",
            "   - A residual connection and layer normalization are applied after each sub-layer to stabilize training and help with the gradient flow.\n",
            "\n",
            "3. **Decoder:**\n",
            "   - Similar to the encoder, the decoder is also composed of stacked layers. Each layer in the decoder has an additional sub-layer for encoder-decoder attention, which allows the decoder to focus on relevant parts of the encoder's output.\n",
            "   - **Masked Multi-head Self-Attention:** In the decoder, a mask is applied to prevent attending to future tokens, ensuring the model generates the output sequence autoregressively.\n",
            "   - **Encoder-Decoder Attention:** This mechanism allows the decoder to attend to the encoder's output, focusing on relevant parts of the input sentence for generating the translation.\n",
            "\n",
            "4. **Output Generation:**\n",
            "   - The decoder generates the output sequence token by token. At each step, it uses the previously generated tokens as input, along with the encoder's output, to produce the next token.\n",
            "   - The process continues until an end-of-sequence token is generated, which signifies the completion of the translation.\n",
            "\n",
            "5. **Final Output:**\n",
            "   - The sequence of tokens produced by the decoder is then converted back into a sentence in the target language. For example, if translating to French, the output might be \"Le chat s'est assis sur le tapis.\"\n",
            "\n",
            "The Transformer model's ability to parallelize computations across all tokens and its use of attention mechanisms allow it to efficiently capture dependencies across the entire input sequence, leading to high-quality translations.\n"
          ]
        }
      ]
    }
  ]
}